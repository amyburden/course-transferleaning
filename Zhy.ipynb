{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "# theano.config.device = 'gpu'\n",
    "# theano.config.floatX = 'float32'\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "num_class = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializations import normal\n",
    "\n",
    "\n",
    "def getModel( output_dim ):\n",
    "    ''' \n",
    "        * output_dim: the number of classes (int)\n",
    "        * return: compiled model (keras.engine.training.Model)\n",
    "    '''\n",
    "    vgg_model = VGG16( weights='imagenet', include_top=True )\n",
    "    vgg_out = vgg_model.layers[-2].output #Last FC layer's output  \n",
    "    softmax_layer = Dense(output_dim, activation='softmax')(vgg_out) #Create softmax layer taking input as vgg_out\n",
    "    #Create new transfer learning model\n",
    "    tl_model = Model( input=vgg_model.input, output=softmax_layer )\n",
    "\n",
    "    #Freeze all layers of VGG16 and Compile the model\n",
    "    for layer in vgg_model.layers:\n",
    "        layer.trainable = False\n",
    "    #Confirm the model is appropriate\n",
    "    return tl_model\n",
    "\n",
    "model = getModel(num_class)\n",
    "# sgd = SGD(lr=1e-3, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def list_gen():\n",
    "    root_dir = '../256_ObjectCategories/'\n",
    "    image_dirs = glob.glob(root_dir + '*')\n",
    "    d = defaultdict(list)\n",
    "    for idir in image_dirs:\n",
    "        all_images = glob.glob(idir + '/*.jpg')\n",
    "        label_id = int(idir.split('/')[-1].split('.')[0])-1\n",
    "        if label_id > 255:\n",
    "            continue\n",
    "        np.random.shuffle(all_images)\n",
    "        train_paths, val_paths, test_paths = all_images[:len(all_images)/10*8], all_images[len(all_images)/10*8:len(all_images)/10*9], all_images[len(all_images)/10*9:]\n",
    "        train_labels, val_labels, test_labels = [label_id]*(len(all_images)/10*8), [label_id]*(len(all_images)/10), [label_id]*(len(all_images)/10)\n",
    "        \n",
    "        d['train_images'].append(train_paths)\n",
    "        d['val_images'].append(val_paths)\n",
    "        d['test_images'].append(test_paths)\n",
    "        d['train_labels'].append(train_labels)\n",
    "        d['val_labels'].append(val_labels)\n",
    "        d['test_labels'].append(test_labels)\n",
    "    return d\n",
    "\n",
    "all_d = list_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def load_data(image_paths, labels, crop_size):\n",
    "    X = np.zeros((len(image_paths), crop_size, crop_size, 3))\n",
    "    for i,path in enumerate(image_paths):\n",
    "        X[i, :] = img_to_array(load_img(path, target_size=(crop_size, crop_size)))\n",
    "    y = np_utils.to_categorical(labels)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crop_size = 224\n",
    "all_per_class = 16\n",
    "train_paths = []\n",
    "val_paths = []\n",
    "test_paths = []\n",
    "train_labels = []\n",
    "val_labels = []\n",
    "test_labels = []\n",
    "for i in xrange(num_class):\n",
    "    train_paths += (all_d['train_images'][i][:all_per_class])\n",
    "    val_paths += (all_d['val_images'][i][:all_per_class])\n",
    "    test_paths += (all_d['test_images'][i][:all_per_class])\n",
    "    train_labels += (all_d['train_labels'][i][:all_per_class])\n",
    "    val_labels += (all_d['val_labels'][i][:all_per_class])\n",
    "    test_labels += (all_d['test_labels'][i][:all_per_class])\n",
    "\n",
    "X_train, y_train = load_data(train_paths, train_labels, crop_size)\n",
    "X_val, y_val = load_data(val_paths, val_labels, crop_size)\n",
    "X_test, y_test = load_data(test_paths, test_labels, crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = preprocess_input(X_train)\n",
    "X_val = preprocess_input(X_val)\n",
    "X_test = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "    rescale=1./128)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "512/512 [==============================] - 6s - loss: 10.2884 - acc: 0.0020 - val_loss: 7.5286 - val_acc: 0.0039\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 6s - loss: 6.5496 - acc: 0.0137 - val_loss: 6.1474 - val_acc: 0.0078\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 6s - loss: 5.7005 - acc: 0.0215 - val_loss: 5.9528 - val_acc: 0.0430\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 6s - loss: 5.0559 - acc: 0.0391 - val_loss: 5.8071 - val_acc: 0.0391\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 6s - loss: 4.4553 - acc: 0.0723 - val_loss: 5.2556 - val_acc: 0.0938\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 6s - loss: 3.8692 - acc: 0.1270 - val_loss: 5.0214 - val_acc: 0.0781\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 6s - loss: 3.3450 - acc: 0.1992 - val_loss: 4.7153 - val_acc: 0.1016\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 7s - loss: 2.8636 - acc: 0.2676 - val_loss: 5.1866 - val_acc: 0.0820\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 7s - loss: 2.4506 - acc: 0.3711 - val_loss: 4.6340 - val_acc: 0.1133\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 7s - loss: 2.0752 - acc: 0.4453 - val_loss: 4.7462 - val_acc: 0.0898\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 7s - loss: 1.7561 - acc: 0.5195 - val_loss: 4.7089 - val_acc: 0.1016\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 7s - loss: 1.4704 - acc: 0.6094 - val_loss: 4.6491 - val_acc: 0.1016\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 7s - loss: 1.2475 - acc: 0.6797 - val_loss: 4.5888 - val_acc: 0.1055\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 7s - loss: 1.0405 - acc: 0.7637 - val_loss: 4.7318 - val_acc: 0.1094\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 7s - loss: 0.8781 - acc: 0.7988 - val_loss: 4.6522 - val_acc: 0.1289\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 7s - loss: 0.7215 - acc: 0.8711 - val_loss: 4.9535 - val_acc: 0.1094\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 7s - loss: 0.6077 - acc: 0.8926 - val_loss: 4.4612 - val_acc: 0.1680\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 7s - loss: 0.4761 - acc: 0.9219 - val_loss: 4.3613 - val_acc: 0.1260\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 7s - loss: 0.4182 - acc: 0.9414 - val_loss: 4.3774 - val_acc: 0.1289\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 7s - loss: 0.3184 - acc: 0.9668 - val_loss: 4.6080 - val_acc: 0.1680\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 7s - loss: 0.2846 - acc: 0.9707 - val_loss: 4.6771 - val_acc: 0.1680\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 7s - loss: 0.2071 - acc: 0.9844 - val_loss: 4.9136 - val_acc: 0.1602\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 7s - loss: 0.2005 - acc: 0.9805 - val_loss: 4.2638 - val_acc: 0.2227\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 7s - loss: 0.1314 - acc: 0.9922 - val_loss: 5.3253 - val_acc: 0.1484\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 7s - loss: 0.1440 - acc: 0.9902 - val_loss: 4.9024 - val_acc: 0.1758\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 7s - loss: 0.0955 - acc: 0.9961 - val_loss: 4.9216 - val_acc: 0.1797\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 7s - loss: 0.0917 - acc: 1.0000 - val_loss: 4.6634 - val_acc: 0.1719\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 7s - loss: 0.0630 - acc: 1.0000 - val_loss: 4.7903 - val_acc: 0.1836\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 7s - loss: 0.0566 - acc: 1.0000 - val_loss: 5.1600 - val_acc: 0.1850\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 7s - loss: 0.0491 - acc: 1.0000 - val_loss: 4.8259 - val_acc: 0.2539\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 7s - loss: 0.0489 - acc: 0.9980 - val_loss: 5.0140 - val_acc: 0.1797\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 7s - loss: 0.0329 - acc: 0.9980 - val_loss: 5.4190 - val_acc: 0.1836\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 7s - loss: 0.0281 - acc: 1.0000 - val_loss: 4.8634 - val_acc: 0.2500\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 7s - loss: 0.0286 - acc: 0.9980 - val_loss: 5.0347 - val_acc: 0.2188\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 7s - loss: 0.0175 - acc: 1.0000 - val_loss: 4.7536 - val_acc: 0.2461\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 7s - loss: 0.0181 - acc: 1.0000 - val_loss: 5.2903 - val_acc: 0.2188\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 7s - loss: 0.0144 - acc: 1.0000 - val_loss: 4.7819 - val_acc: 0.2656\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 7s - loss: 0.0139 - acc: 1.0000 - val_loss: 5.0998 - val_acc: 0.2422\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 7s - loss: 0.0134 - acc: 1.0000 - val_loss: 5.3933 - val_acc: 0.2383\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 7s - loss: 0.0085 - acc: 1.0000 - val_loss: 5.1582 - val_acc: 0.2598\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 7s - loss: 0.0064 - acc: 1.0000 - val_loss: 4.8670 - val_acc: 0.2461\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 7s - loss: 0.0068 - acc: 1.0000 - val_loss: 5.0336 - val_acc: 0.2578\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 7s - loss: 0.0072 - acc: 1.0000 - val_loss: 5.4436 - val_acc: 0.2305\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 7s - loss: 0.0102 - acc: 1.0000 - val_loss: 5.2773 - val_acc: 0.2344\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 7s - loss: 0.0093 - acc: 0.9980 - val_loss: 5.6197 - val_acc: 0.2578\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 7s - loss: 0.0059 - acc: 1.0000 - val_loss: 5.7289 - val_acc: 0.2305\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 7s - loss: 0.0044 - acc: 1.0000 - val_loss: 5.3417 - val_acc: 0.2617\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 7s - loss: 0.0023 - acc: 1.0000 - val_loss: 4.6359 - val_acc: 0.2773\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 7s - loss: 0.0020 - acc: 1.0000 - val_loss: 5.4959 - val_acc: 0.2656\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 7s - loss: 0.0041 - acc: 1.0000 - val_loss: 5.5371 - val_acc: 0.2812\n",
      "Epoch 1/50\n",
      "1024/1024 [==============================] - 10s - loss: 8.4530 - acc: 0.0068 - val_loss: 6.3047 - val_acc: 0.0195\n",
      "Epoch 2/50\n",
      "1024/1024 [==============================] - 11s - loss: 5.8445 - acc: 0.0352 - val_loss: 5.4979 - val_acc: 0.0781\n",
      "Epoch 3/50\n",
      "1024/1024 [==============================] - 12s - loss: 5.0605 - acc: 0.0518 - val_loss: 5.3475 - val_acc: 0.0430\n",
      "Epoch 4/50\n",
      "1024/1024 [==============================] - 11s - loss: 4.2595 - acc: 0.1035 - val_loss: 4.8547 - val_acc: 0.0586\n",
      "Epoch 5/50\n",
      "1024/1024 [==============================] - 11s - loss: 3.6395 - acc: 0.1621 - val_loss: 4.6186 - val_acc: 0.0898\n",
      "Epoch 6/50\n",
      "1024/1024 [==============================] - 11s - loss: 3.0972 - acc: 0.2422 - val_loss: 4.3885 - val_acc: 0.1220\n",
      "Epoch 7/50\n",
      "1024/1024 [==============================] - 11s - loss: 2.6568 - acc: 0.3125 - val_loss: 4.2413 - val_acc: 0.1367\n",
      "Epoch 8/50\n",
      "1024/1024 [==============================] - 11s - loss: 2.2798 - acc: 0.3877 - val_loss: 4.1522 - val_acc: 0.1797\n",
      "Epoch 9/50\n",
      "1024/1024 [==============================] - 11s - loss: 1.9605 - acc: 0.4707 - val_loss: 4.2091 - val_acc: 0.1328\n",
      "Epoch 10/50\n",
      "1024/1024 [==============================] - 12s - loss: 1.6994 - acc: 0.5273 - val_loss: 4.1022 - val_acc: 0.1445\n",
      "Epoch 11/50\n",
      "1024/1024 [==============================] - 11s - loss: 1.4651 - acc: 0.5820 - val_loss: 4.2993 - val_acc: 0.1562\n",
      "Epoch 12/50\n",
      "1024/1024 [==============================] - 12s - loss: 1.2678 - acc: 0.6387 - val_loss: 4.0507 - val_acc: 0.2244\n",
      "Epoch 13/50\n",
      "1024/1024 [==============================] - 12s - loss: 1.0968 - acc: 0.6934 - val_loss: 3.9979 - val_acc: 0.1914\n",
      "Epoch 14/50\n",
      "1024/1024 [==============================] - 12s - loss: 0.9523 - acc: 0.7383 - val_loss: 4.4653 - val_acc: 0.1836\n",
      "Epoch 15/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.8179 - acc: 0.7822 - val_loss: 3.9983 - val_acc: 0.2305\n",
      "Epoch 16/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.7077 - acc: 0.8213 - val_loss: 4.1590 - val_acc: 0.2188\n",
      "Epoch 17/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.6083 - acc: 0.8506 - val_loss: 3.6520 - val_acc: 0.2891\n",
      "Epoch 18/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.5251 - acc: 0.8750 - val_loss: 4.2259 - val_acc: 0.2812\n",
      "Epoch 19/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.4443 - acc: 0.8955 - val_loss: 3.8428 - val_acc: 0.2461\n",
      "Epoch 20/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.3878 - acc: 0.9121 - val_loss: 3.6276 - val_acc: 0.3047\n",
      "Epoch 21/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.3309 - acc: 0.9248 - val_loss: 4.0893 - val_acc: 0.2578\n",
      "Epoch 22/50\n",
      "1024/1024 [==============================] - 12s - loss: 0.2834 - acc: 0.9355 - val_loss: 3.9836 - val_acc: 0.2852\n",
      "Epoch 23/50\n",
      "1024/1024 [==============================] - 12s - loss: 0.2391 - acc: 0.9551 - val_loss: 4.3776 - val_acc: 0.2992\n",
      "Epoch 24/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.2011 - acc: 0.9609 - val_loss: 4.4554 - val_acc: 0.2500\n",
      "Epoch 25/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.1802 - acc: 0.9668 - val_loss: 3.7131 - val_acc: 0.3047\n",
      "Epoch 26/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.1475 - acc: 0.9766 - val_loss: 4.3212 - val_acc: 0.2734\n",
      "Epoch 27/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.1392 - acc: 0.9775 - val_loss: 3.8976 - val_acc: 0.3242\n",
      "Epoch 28/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.1103 - acc: 0.9824 - val_loss: 4.3728 - val_acc: 0.2930\n",
      "Epoch 29/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.1067 - acc: 0.9775 - val_loss: 3.7627 - val_acc: 0.3477\n",
      "Epoch 30/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0796 - acc: 0.9834 - val_loss: 4.6760 - val_acc: 0.2695\n",
      "Epoch 31/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0765 - acc: 0.9844 - val_loss: 4.1453 - val_acc: 0.3516\n",
      "Epoch 32/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0619 - acc: 0.9863 - val_loss: 3.9664 - val_acc: 0.3086\n",
      "Epoch 33/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0605 - acc: 0.9883 - val_loss: 4.1768 - val_acc: 0.3086\n",
      "Epoch 34/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0532 - acc: 0.9902 - val_loss: 4.1502 - val_acc: 0.2969\n",
      "Epoch 35/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0458 - acc: 0.9932 - val_loss: 3.9648 - val_acc: 0.3594\n",
      "Epoch 36/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0504 - acc: 0.9922 - val_loss: 4.2597 - val_acc: 0.3516\n",
      "Epoch 37/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0417 - acc: 0.9912 - val_loss: 3.6768 - val_acc: 0.3945\n",
      "Epoch 38/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0352 - acc: 0.9932 - val_loss: 4.2218 - val_acc: 0.3867\n",
      "Epoch 39/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0315 - acc: 0.9941 - val_loss: 4.3717 - val_acc: 0.3359\n",
      "Epoch 40/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0288 - acc: 0.9951 - val_loss: 4.7382 - val_acc: 0.3477\n",
      "Epoch 41/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0273 - acc: 0.9941 - val_loss: 4.1433 - val_acc: 0.3203\n",
      "Epoch 42/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0206 - acc: 0.9971 - val_loss: 4.0137 - val_acc: 0.3672\n",
      "Epoch 43/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0208 - acc: 0.9961 - val_loss: 4.3294 - val_acc: 0.3633\n",
      "Epoch 44/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0136 - acc: 0.9980 - val_loss: 4.4832 - val_acc: 0.3594\n",
      "Epoch 45/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0198 - acc: 0.9971 - val_loss: 4.2977 - val_acc: 0.3594\n",
      "Epoch 46/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0143 - acc: 0.9980 - val_loss: 4.1261 - val_acc: 0.3359\n",
      "Epoch 47/50\n",
      "1024/1024 [==============================] - 12s - loss: 0.0132 - acc: 0.9980 - val_loss: 5.2795 - val_acc: 0.3047\n",
      "Epoch 48/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0124 - acc: 0.9990 - val_loss: 4.5538 - val_acc: 0.3359\n",
      "Epoch 49/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0109 - acc: 0.9971 - val_loss: 4.0615 - val_acc: 0.3867\n",
      "Epoch 50/50\n",
      "1024/1024 [==============================] - 11s - loss: 0.0103 - acc: 0.9990 - val_loss: 4.2987 - val_acc: 0.3359\n",
      "Epoch 1/50\n",
      "2048/2048 [==============================] - 19s - loss: 7.5096 - acc: 0.0151 - val_loss: 6.1282 - val_acc: 0.0312\n",
      "Epoch 2/50\n",
      "2048/2048 [==============================] - 20s - loss: 5.3622 - acc: 0.0532 - val_loss: 5.0143 - val_acc: 0.0938\n",
      "Epoch 3/50\n",
      "2048/2048 [==============================] - 20s - loss: 4.3356 - acc: 0.1187 - val_loss: 4.5722 - val_acc: 0.0781\n",
      "Epoch 4/50\n",
      "2048/2048 [==============================] - 20s - loss: 3.6092 - acc: 0.1875 - val_loss: 4.2179 - val_acc: 0.1211\n",
      "Epoch 5/50\n",
      "2048/2048 [==============================] - 20s - loss: 3.0595 - acc: 0.2598 - val_loss: 3.7447 - val_acc: 0.2031\n",
      "Epoch 6/50\n",
      "2048/2048 [==============================] - 21s - loss: 2.6331 - acc: 0.3467 - val_loss: 3.7156 - val_acc: 0.2031\n",
      "Epoch 7/50\n",
      "2048/2048 [==============================] - 20s - loss: 2.2938 - acc: 0.4185 - val_loss: 4.0010 - val_acc: 0.2031\n",
      "Epoch 8/50\n",
      "2048/2048 [==============================] - 20s - loss: 2.0127 - acc: 0.4756 - val_loss: 3.2841 - val_acc: 0.2812\n",
      "Epoch 9/50\n",
      "2048/2048 [==============================] - 20s - loss: 1.7785 - acc: 0.5298 - val_loss: 3.2946 - val_acc: 0.3047\n",
      "Epoch 10/50\n",
      "2048/2048 [==============================] - 21s - loss: 1.5863 - acc: 0.5728 - val_loss: 3.0988 - val_acc: 0.3633\n",
      "Epoch 11/50\n",
      "2048/2048 [==============================] - 20s - loss: 1.4160 - acc: 0.6240 - val_loss: 3.6344 - val_acc: 0.3359\n",
      "Epoch 12/50\n",
      "2048/2048 [==============================] - 20s - loss: 1.2669 - acc: 0.6606 - val_loss: 3.1026 - val_acc: 0.3228\n",
      "Epoch 13/50\n",
      "2048/2048 [==============================] - 20s - loss: 1.1344 - acc: 0.6992 - val_loss: 3.0679 - val_acc: 0.3750\n",
      "Epoch 14/50\n",
      "2048/2048 [==============================] - 20s - loss: 1.0158 - acc: 0.7251 - val_loss: 3.2873 - val_acc: 0.3203\n",
      "Epoch 15/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.9113 - acc: 0.7583 - val_loss: 3.7148 - val_acc: 0.3320\n",
      "Epoch 16/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.8205 - acc: 0.7817 - val_loss: 3.3433 - val_acc: 0.3594\n",
      "Epoch 17/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.7390 - acc: 0.8057 - val_loss: 2.9846 - val_acc: 0.4141\n",
      "Epoch 18/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.6648 - acc: 0.8262 - val_loss: 3.1094 - val_acc: 0.4173\n",
      "Epoch 19/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.5934 - acc: 0.8428 - val_loss: 3.1744 - val_acc: 0.3945\n",
      "Epoch 20/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.5322 - acc: 0.8525 - val_loss: 3.5822 - val_acc: 0.3672\n",
      "Epoch 21/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.4799 - acc: 0.8687 - val_loss: 2.6484 - val_acc: 0.4492\n",
      "Epoch 22/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.4247 - acc: 0.8901 - val_loss: 3.2393 - val_acc: 0.4336\n",
      "Epoch 23/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.3837 - acc: 0.9004 - val_loss: 3.3886 - val_acc: 0.3945\n",
      "Epoch 24/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.3402 - acc: 0.9141 - val_loss: 3.7630 - val_acc: 0.3740\n",
      "Epoch 25/50\n",
      "2048/2048 [==============================] - 21s - loss: 0.3059 - acc: 0.9268 - val_loss: 2.8952 - val_acc: 0.4414\n",
      "Epoch 26/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.2794 - acc: 0.9312 - val_loss: 3.2834 - val_acc: 0.4062\n",
      "Epoch 27/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.2496 - acc: 0.9409 - val_loss: 3.5611 - val_acc: 0.3516\n",
      "Epoch 28/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.2302 - acc: 0.9443 - val_loss: 4.2639 - val_acc: 0.3750\n",
      "Epoch 29/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.2026 - acc: 0.9478 - val_loss: 3.1017 - val_acc: 0.4531\n",
      "Epoch 30/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.1824 - acc: 0.9551 - val_loss: 3.4614 - val_acc: 0.4016\n",
      "Epoch 31/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.1632 - acc: 0.9575 - val_loss: 3.8101 - val_acc: 0.3984\n",
      "Epoch 32/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.1571 - acc: 0.9590 - val_loss: 3.4157 - val_acc: 0.4219\n",
      "Epoch 33/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.1402 - acc: 0.9663 - val_loss: 3.8101 - val_acc: 0.3984\n",
      "Epoch 34/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.1230 - acc: 0.9697 - val_loss: 3.9234 - val_acc: 0.3789\n",
      "Epoch 35/50\n",
      "2048/2048 [==============================] - 21s - loss: 0.1101 - acc: 0.9741 - val_loss: 3.7839 - val_acc: 0.4219\n",
      "Epoch 36/50\n",
      "2048/2048 [==============================] - 21s - loss: 0.1003 - acc: 0.9780 - val_loss: 3.4619 - val_acc: 0.4688\n",
      "Epoch 37/50\n",
      "2048/2048 [==============================] - 21s - loss: 0.0941 - acc: 0.9780 - val_loss: 3.6488 - val_acc: 0.3594\n",
      "Epoch 38/50\n",
      "2048/2048 [==============================] - 21s - loss: 0.0891 - acc: 0.9810 - val_loss: 3.7438 - val_acc: 0.3906\n",
      "Epoch 39/50\n",
      "2048/2048 [==============================] - 21s - loss: 0.0783 - acc: 0.9849 - val_loss: 3.7511 - val_acc: 0.4609\n",
      "Epoch 40/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.0735 - acc: 0.9839 - val_loss: 4.0274 - val_acc: 0.3906\n",
      "Epoch 41/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.0667 - acc: 0.9844 - val_loss: 3.9012 - val_acc: 0.4449\n",
      "Epoch 42/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.0657 - acc: 0.9839 - val_loss: 3.7925 - val_acc: 0.4453\n",
      "Epoch 43/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.0615 - acc: 0.9858 - val_loss: 3.4868 - val_acc: 0.4492\n",
      "Epoch 44/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.0514 - acc: 0.9888 - val_loss: 3.8340 - val_acc: 0.4375\n",
      "Epoch 45/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.0519 - acc: 0.9883 - val_loss: 4.1021 - val_acc: 0.4414\n",
      "Epoch 46/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.0491 - acc: 0.9893 - val_loss: 3.6070 - val_acc: 0.4453\n",
      "Epoch 47/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.0454 - acc: 0.9902 - val_loss: 4.0875 - val_acc: 0.4258\n",
      "Epoch 48/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.0430 - acc: 0.9897 - val_loss: 3.8164 - val_acc: 0.4375\n",
      "Epoch 49/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.0457 - acc: 0.9873 - val_loss: 3.5988 - val_acc: 0.4805\n",
      "Epoch 50/50\n",
      "2048/2048 [==============================] - 20s - loss: 0.0386 - acc: 0.9907 - val_loss: 3.9619 - val_acc: 0.4492\n",
      "Epoch 1/50\n",
      "4096/4096 [==============================] - 37s - loss: 6.4977 - acc: 0.0291 - val_loss: 5.1014 - val_acc: 0.0508\n",
      "Epoch 2/50\n",
      "4096/4096 [==============================] - 39s - loss: 4.3510 - acc: 0.1228 - val_loss: 4.3140 - val_acc: 0.1914\n",
      "Epoch 3/50\n",
      "4096/4096 [==============================] - 39s - loss: 3.4170 - acc: 0.2329 - val_loss: 3.5394 - val_acc: 0.2500\n",
      "Epoch 4/50\n",
      "4096/4096 [==============================] - 39s - loss: 2.8458 - acc: 0.3264 - val_loss: 3.6144 - val_acc: 0.2031\n",
      "Epoch 5/50\n",
      "4096/4096 [==============================] - 39s - loss: 2.4460 - acc: 0.4026 - val_loss: 3.2732 - val_acc: 0.2852\n",
      "Epoch 6/50\n",
      "4096/4096 [==============================] - 39s - loss: 2.1460 - acc: 0.4724 - val_loss: 3.0447 - val_acc: 0.3828\n",
      "Epoch 7/50\n",
      "4096/4096 [==============================] - 39s - loss: 1.9155 - acc: 0.5239 - val_loss: 3.0068 - val_acc: 0.3906\n",
      "Epoch 8/50\n",
      "4096/4096 [==============================] - 39s - loss: 1.7280 - acc: 0.5691 - val_loss: 2.9895 - val_acc: 0.3945\n",
      "Epoch 9/50\n",
      "4096/4096 [==============================] - 39s - loss: 1.5717 - acc: 0.6099 - val_loss: 3.2345 - val_acc: 0.3867\n",
      "Epoch 10/50\n",
      "4096/4096 [==============================] - 39s - loss: 1.4375 - acc: 0.6423 - val_loss: 2.9900 - val_acc: 0.3750\n",
      "Epoch 11/50\n",
      "4096/4096 [==============================] - 39s - loss: 1.3197 - acc: 0.6733 - val_loss: 2.8878 - val_acc: 0.4453\n",
      "Epoch 12/50\n",
      "4096/4096 [==============================] - 39s - loss: 1.2137 - acc: 0.6968 - val_loss: 3.0043 - val_acc: 0.4453\n",
      "Epoch 13/50\n",
      "4096/4096 [==============================] - 39s - loss: 1.1197 - acc: 0.7188 - val_loss: 2.6508 - val_acc: 0.4805\n",
      "Epoch 14/50\n",
      "4096/4096 [==============================] - 39s - loss: 1.0380 - acc: 0.7388 - val_loss: 2.8839 - val_acc: 0.4727\n",
      "Epoch 15/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.9626 - acc: 0.7563 - val_loss: 3.0167 - val_acc: 0.4180\n",
      "Epoch 16/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.8950 - acc: 0.7734 - val_loss: 3.0748 - val_acc: 0.4297\n",
      "Epoch 17/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.8333 - acc: 0.7883 - val_loss: 2.6676 - val_acc: 0.4648\n",
      "Epoch 18/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.7778 - acc: 0.8042 - val_loss: 2.8488 - val_acc: 0.4961\n",
      "Epoch 19/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.7256 - acc: 0.8188 - val_loss: 3.0684 - val_acc: 0.4688\n",
      "Epoch 20/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.6797 - acc: 0.8262 - val_loss: 2.7374 - val_acc: 0.5156\n",
      "Epoch 21/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.6386 - acc: 0.8398 - val_loss: 2.6478 - val_acc: 0.5117\n",
      "Epoch 22/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.5993 - acc: 0.8496 - val_loss: 2.8191 - val_acc: 0.5117\n",
      "Epoch 23/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.5638 - acc: 0.8604 - val_loss: 2.7634 - val_acc: 0.5430\n",
      "Epoch 24/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.5309 - acc: 0.8667 - val_loss: 2.6866 - val_acc: 0.5039\n",
      "Epoch 25/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.4944 - acc: 0.8767 - val_loss: 3.1330 - val_acc: 0.4883\n",
      "Epoch 26/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.4636 - acc: 0.8843 - val_loss: 3.2092 - val_acc: 0.4531\n",
      "Epoch 27/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.4356 - acc: 0.8906 - val_loss: 2.5653 - val_acc: 0.5391\n",
      "Epoch 28/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.4115 - acc: 0.8972 - val_loss: 3.0230 - val_acc: 0.5273\n",
      "Epoch 29/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.3856 - acc: 0.9067 - val_loss: 3.2831 - val_acc: 0.4414\n",
      "Epoch 30/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.3612 - acc: 0.9111 - val_loss: 3.2927 - val_acc: 0.4724\n",
      "Epoch 31/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.3431 - acc: 0.9155 - val_loss: 2.7877 - val_acc: 0.5078\n",
      "Epoch 32/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.3176 - acc: 0.9214 - val_loss: 3.0555 - val_acc: 0.5117\n",
      "Epoch 33/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.3001 - acc: 0.9255 - val_loss: 3.1472 - val_acc: 0.5156\n",
      "Epoch 34/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.2844 - acc: 0.9302 - val_loss: 2.8081 - val_acc: 0.5586\n",
      "Epoch 35/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.2639 - acc: 0.9333 - val_loss: 2.9761 - val_acc: 0.5547\n",
      "Epoch 36/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.2538 - acc: 0.9385 - val_loss: 3.3499 - val_acc: 0.4803\n",
      "Epoch 37/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.2427 - acc: 0.9412 - val_loss: 2.5670 - val_acc: 0.5742\n",
      "Epoch 38/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.2297 - acc: 0.9446 - val_loss: 3.0347 - val_acc: 0.5312\n",
      "Epoch 39/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.2209 - acc: 0.9456 - val_loss: 2.6050 - val_acc: 0.5156\n",
      "Epoch 40/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.2057 - acc: 0.9526 - val_loss: 2.8806 - val_acc: 0.5391\n",
      "Epoch 41/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.1906 - acc: 0.9546 - val_loss: 3.4844 - val_acc: 0.5039\n",
      "Epoch 42/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.1842 - acc: 0.9573 - val_loss: 3.1740 - val_acc: 0.5352\n",
      "Epoch 43/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.1768 - acc: 0.9607 - val_loss: 3.4956 - val_acc: 0.5234\n",
      "Epoch 44/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.1664 - acc: 0.9607 - val_loss: 3.1499 - val_acc: 0.5273\n",
      "Epoch 45/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.1579 - acc: 0.9622 - val_loss: 3.4685 - val_acc: 0.5078\n",
      "Epoch 46/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.1560 - acc: 0.9607 - val_loss: 3.2492 - val_acc: 0.5273\n",
      "Epoch 47/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.1422 - acc: 0.9646 - val_loss: 3.3802 - val_acc: 0.4648\n",
      "Epoch 48/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.1363 - acc: 0.9670 - val_loss: 3.1693 - val_acc: 0.4961\n",
      "Epoch 49/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.1308 - acc: 0.9680 - val_loss: 3.0463 - val_acc: 0.5391\n",
      "Epoch 50/50\n",
      "4096/4096 [==============================] - 39s - loss: 0.1235 - acc: 0.9680 - val_loss: 4.1001 - val_acc: 0.4805\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 50\n",
    "batch_size = 64\n",
    "\n",
    "for sample_per_class in [2,4,8,16]:\n",
    "    train = X_train.reshape((num_class, -1, crop_size, crop_size, 3))\n",
    "    train = train[:, :sample_per_class].reshape((-1, crop_size, crop_size, 3))\n",
    "    label = y_train.reshape((num_class, -1, num_class))\n",
    "    label = label[:, :sample_per_class].reshape((-1, num_class))\n",
    "    rmsmodel = getModel(num_class)\n",
    "    rmsmodel.compile(optimizer='rmsprop',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "    rmsmodel.fit_generator(datagen.flow(train, label, batch_size=32),\n",
    "                           validation_data=datagen.flow(X_val, y_val, batch_size=batch_size),\n",
    "                           nb_val_samples=200,\n",
    "                           samples_per_epoch=len(train), nb_epoch=num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loss=[[],[],[],[]]\n",
    "val_loss=[[],[],[],[]]\n",
    "train_accu=[[],[],[],[]]\n",
    "val_accu=[[],[],[],[]]\n",
    "with open('log', 'r') as f:\n",
    "    for line in f:\n",
    "        exp = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting\n",
    "# loss vs epoch\n",
    "plt.figure()\n",
    "for i,sample_size in enumerate([2,4,8,16]):\n",
    "    plt.plot(range(num_epoch), train_loss[i], 'b-', label='{} samples /class training'.format(sample_size))\n",
    "    plt.plot(range(num_epoch), val_loss[i], 'b.', label='{} samples /class validation'.format(sample_size))\n",
    "plt.title('loss vs # of epochs')\n",
    "plt.legend('top right')\n",
    "plt.xlabel('# of epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig('images/4a.pdf')\n",
    "plt.show()\n",
    "\n",
    "# accu vs epoch\n",
    "plt.figure()\n",
    "for i,sample_size in enumerate([2,4,8,16]):\n",
    "    plt.plot(range(num_epoch), train_accu[i], 'b-', label='{} samples /class training'.format(sample_size))\n",
    "    plt.plot(range(num_epoch), val_accu[i], 'b.', label='{} samples /class validation'.format(sample_size))\n",
    "plt.title('accuracy vs # of epochs')\n",
    "plt.legend('top right')\n",
    "plt.xlabel('# of epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('images/4b.pdf')\n",
    "plt.show()\n",
    "\n",
    "# training sample vs accu\n",
    "plt.figure()\n",
    "plt.plot([2,4,8,16], [train_accu[i][-1] for i in xrange(4)], label='train')\n",
    "plt.plot([2,4,8,16], [val_accu[i][-1] for i in xrange(4)], label='val')\n",
    "plt.xscale('log')\n",
    "plt.title('accuracy vs # of samples')\n",
    "plt.legend('top right')\n",
    "plt.xlabel('# of samples')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('images/4c.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1024/1024 [==============================] - 302s - loss: 8.6288 - acc: 0.0088   \n",
      "Epoch 2/10\n",
      "1024/1024 [==============================] - 304s - loss: 6.0655 - acc: 0.0332   \n",
      "Epoch 3/10\n",
      "1024/1024 [==============================] - 304s - loss: 5.1832 - acc: 0.0654   \n",
      "Epoch 4/10\n",
      "1024/1024 [==============================] - 304s - loss: 4.4927 - acc: 0.1006   \n",
      "Epoch 5/10\n",
      "1024/1024 [==============================] - 305s - loss: 3.8219 - acc: 0.1445   \n",
      "Epoch 6/10\n",
      "1024/1024 [==============================] - 306s - loss: 3.3476 - acc: 0.2168   \n",
      "Epoch 7/10\n",
      "1024/1024 [==============================] - 312s - loss: 2.8463 - acc: 0.2979   \n",
      "Epoch 8/10\n",
      " 384/1024 [==========>...................] - ETA: 193s - loss: 2.6298 - acc: 0.3047"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-40be58d439a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m      6\u001b[0m rmsmodel.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n\u001b[1;32m----> 7\u001b[1;33m                     samples_per_epoch=len(X_train), nb_epoch=10)\n\u001b[0m",
      "\u001b[1;32m/home/zhipeng_yan/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1555\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1556\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1557\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1559\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhipeng_yan/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhipeng_yan/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 1943\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   1944\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhipeng_yan/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhipeng_yan/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhipeng_yan/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/zhipeng_yan/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zhipeng_yan/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = getModel(num_class)\n",
    "# sgd = SGD(lr=1e-3, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    samples_per_epoch=len(X_train), nb_epoch=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
